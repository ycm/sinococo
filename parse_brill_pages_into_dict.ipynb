{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1986b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff60ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brill/entries/i-000052') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "soup = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd7df9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('div', {'class': 'middle-column clearfix'})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e4b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i-008353\r"
     ]
    }
   ],
   "source": [
    "entries = {}\n",
    "for file in sorted(os.listdir('brill/entries/')):\n",
    "    print(file, end='\\r')\n",
    "    with open(os.path.join('brill', 'entries', file)) as f:\n",
    "        contents = f.read()\n",
    "        soup = BeautifulSoup(contents, 'html.parser')\n",
    "    entries[file] = soup.find_all('div', {'class': 'middle-column clearfix'})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2d2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_element(elem):\n",
    "    while elem is not None:\n",
    "        # Find next element, skip NavigableString objects\n",
    "        elem = elem.next_sibling\n",
    "        if hasattr(elem, 'name'):\n",
    "            return elem\n",
    "        \n",
    "def get_definitions(content):\n",
    "    definitions = []\n",
    "    h3_tags = content.find_all('h3')\n",
    "    for h3tag in h3_tags:\n",
    "        definition = [str(h3tag)]\n",
    "        elem = next_element(h3tag)\n",
    "        while elem and elem.name != 'h3':\n",
    "            definition.append(str(elem))\n",
    "            elem = next_element(elem)\n",
    "        definitions.append('\\n'.join(definition))\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f494428",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICTIONARY = {}\n",
    "for page_id, entry in entries.items():\n",
    "    span_hanzi = entry.find_all('span', {'class': 'hanzi'})\n",
    "    if len(span_hanzi) != 2:\n",
    "        continue\n",
    "    assert span_hanzi[0] == span_hanzi[1]\n",
    "    \n",
    "    # title\n",
    "    h1_book_title = entry.find_all('h1', {'class': 'book-title'})[0]\n",
    "    character = h1_book_title.find('span', {'class': 'hanzi'}).text\n",
    "    pinyin_citation = h1_book_title.text.split()[1].strip()\n",
    "    assert pinyin_citation[0] == '(' and pinyin_citation[-1] == ')'\n",
    "    assert len(character) == 1\n",
    "    \n",
    "    # entry contents\n",
    "    \n",
    "    article = entry.find_all('article', {'class': 'content clearfix english_content'})\n",
    "    assert len(article) == 1\n",
    "    article = article[0]\n",
    "    content = article.find_all('div', {'class': 'english_content'})\n",
    "    assert len(content) == 1\n",
    "    content = content[0]\n",
    "    \n",
    "    # structural (radical, strokes)\n",
    "    structural_desc = content.find_all('p', {'style': 'font-size:smaller;'})\n",
    "    assert len(structural_desc) == 1\n",
    "    structural_desc = ' '.join(structural_desc[0].text.split()).strip()\n",
    "    structural_desc = structural_desc.replace('radical ', '').replace(' strokes', '').split(' + ')\n",
    "    assert len(structural_desc[0]) == 1 and structural_desc[1].isdigit()\n",
    "    radical = structural_desc[0]\n",
    "    n_strokes = int(structural_desc[1])\n",
    "    \n",
    "    # individual entries\n",
    "    definitions = get_definitions(content)\n",
    "    definitions_list = []\n",
    "    for definition in definitions:\n",
    "        definition_dict = {}\n",
    "        definition_soup = BeautifulSoup(definition, 'html.parser')\n",
    "        definition_dict['pinyin'] = definition_soup.find('h3').text\n",
    "        \n",
    "        definition_dict['MC_reconst'] = ' '.join(definition_soup.find('p').text.split()).strip()\n",
    "#         print(definition)\n",
    "        \n",
    "        senses = []\n",
    "        \n",
    "        sense_list = definition_soup.find_all('ol', {'type': '1'})[0]\n",
    "        for sense in sense_list.children:\n",
    "            if sense is not None and sense.text.strip():\n",
    "                sense_li = str(sense).strip()\n",
    "                assert sense_li.startswith('<li>') and sense_li.endswith('</li>')\n",
    "                senses.append(sense_li[4:-5].strip())\n",
    "        \n",
    "        definition_dict['senses'] = senses\n",
    "        definitions_list.append(definition_dict)\n",
    "    \n",
    "    entry_dict = {\n",
    "        'pinyin_citation': pinyin_citation,\n",
    "        'radical': radical,\n",
    "        'additional_strokes': n_strokes,\n",
    "        'definitions': definitions_list\n",
    "    }\n",
    "    DICTIONARY[character] = entry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131b7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('kroll_parse.json', 'x') as f:\n",
    "    json.dump(DICTIONARY, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
